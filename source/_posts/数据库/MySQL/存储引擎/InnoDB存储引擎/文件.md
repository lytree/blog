---
title: 文件
date: 2023-01-21T16:26:24Z
lastmod: 2023-02-14T23:14:11Z
---

# 文件

## redo log(重做日志)

> 存储引擎层面(物理日志)

　　Redo log不是记录数据页“更新之后的状态”，而是记录这个页 “做了什么改动”。

* 当一条记录需要更新的时候，InnoDB引擎会先把记录写到redo log日志中，并更新内存，此时更新算是完成。同时InnoDB会在合适的时间将记录存储到磁盘中去，这个时间往往是服务器空闲时间。
* redo log的大小是固定的可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。

　　​![下载.png](assets/net-img-1624106093230-4372b31c-0d0f-4640-8e80-62b7bdd258e4-20230122192859-kbq2rlz.png)​

* write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。
* write pos 和 checkpoint 之间的是还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示日志文件满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。
* 有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为**crash-safe**

```sql
-- 查看当前redo log大小
show variables like 'innodb_log%';

-- 修改mysql redo log 大小和个数
-- 修改mysql配置文件
innodb_log_file_size=200M
innodb_log_files_in_group = 5
-- 刷盘时机
innodb_flush_log_at_trx_commit=0，（默认）在提交事务时，InnoDB不会立即触发将缓存日志写到磁盘文件的操作，而是每秒触发一次缓存日志回写磁盘操作，并调用操作系统fsync刷新IO缓存。
innodb_flush_log_at_trx_commit=1，在每个事务提交时，InnoDB立即将缓存中的redo日志回写到日志文件，并调用操作系统fsync刷新IO缓存。
innodb_flush_log_at_trx_commit=2，在每个事务提交时，InnoDB立即将缓存中的redo日志回写到日志文件，但并不马上调用fsync来刷新IO缓存，而是每秒只做一次磁盘IO缓存刷新操作。

建议为1，但性能较差
```

### 相关内容：

* 两段式提交[^1]
* Checkpoint技术[^2]

## undolog(回滚日志)

　　‍

[^1]: # 两阶段提交

    ## 两阶段提交(redolog和binlog)

    > 用意：为了保证redolog和binlog数据的安全一致性
    >

    ![下载 (1).png](assets/net-img-1624109586831-fa30fbaf-01b4-4243-bedf-eedfe9631e67-20230122192859-buewr2p.png)

    ### 为何使用两阶段提交

    1. **先写入redo log，再写入binlog**
       1. 先写入redo log 当redo log 写入完毕时，mysql服务进程异常导致mysql重启，因为 redo log已写入完毕，可恢复到发生异常前，但由于binlog没写完就发生异常，导致binlog中没有记录异常前的sql，如果使用binlog回复数据库，就会导致数据库部分数据丢失。
    2. **先写入binlog，再写入redo log**
       1. 如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，在之后用 binlog 来恢复的时候就多了一个事务出来，导致数据库与原库不一致。

    ### 为何有redo log还需要binlog

    * redolog只有InnoDB有，别的引擎没有。
    * redolog是循环写的，不持久保存，binlog的“归档”这个功能，redolog是不具备的。
    * 因为MySQL写数据是写在内存里的，不保证落盘，binlog 没有能力恢复“数据页”。

    ### 为何不能只用 redo log，不要 binlog

    * 如果只从崩溃恢复的角度来讲是可以的。你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。
    * 一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。
    * 一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。

    假设无redo log 流程如下图
    ![下载.jpg](assets/net-img-1628324723790-e7e469c7-62d0-4076-aa53-5e937ae80bee-20230122192859-e7kchm7.jpeg)
    如果在图中标的位置，也就是 binlog2 写完了，但是整个事务还没有 commit 的时候，MySQL 发生了 crash。
    重启后，引擎内部事务 2 会回滚，然后应用 binlog2 可以补回来；但是对于事务 1 来说，系统已经认为提交完成了，不会再应用一次 binlog1。
    但是，InnoDB 引擎使用的是 WAL 技术，执行事务的时候，写完内存和日志，事务就算完成了。如果之后崩溃，要依赖于日志来恢复数据页。
    也就是说在图中这个位置发生崩溃的话，事务 1 也是可能丢失了的，而且是数据页级的丢失。此时，binlog 里面并没有记录数据页的更新细节，是补不回来的。

    ### 处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?

    和数据与备份的一致性有关。在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。  
    所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。

    ### 为何不先 redo log 写完，再写 binlog。崩溃恢复的时候，必须得两个日志都完整才可以。

    两阶段提交是经典的分布式系统问题 ，比如事务的持久性问题。  
    对于 InnoDB 引擎来说，如果 redo log 提交完成了，事务就不能回滚（如果这还允许回滚，就可能覆盖掉别的事务的更新）。而如果 redo log 直接提交，然后 binlog 写入的时候失败，InnoDB 又回滚不了，数据和 binlog 日志又不一致了。  
    两阶段提交就是为了给所有人一个机会，当每个人都说“我 ok”的时候，再一起提交。

    ### redo log 和binlog 区别

    1. redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。
    2. redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，及对应的sql语句
    3. redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

    ### redo log 和 binlog 是怎么关联起来的?

    它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：

    - 如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；
    - 如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务

    ### redo log buffer 是什么？是先修改内存，还是先写 redo log 文件？

    插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。


[^2]: # Checkpoint技术

    ## 目标

    > 为了解决已下问题
    >

    * 缩短数据库恢复时间；
    * 缓冲池不够用时，将脏页刷新到磁盘；
    * 重做日志不可用时，刷新脏页

    ## 实现

    ### Sharp CheckPoint

    > 发生在数据库关闭的时候，将所有脏页都刷新回磁盘
    >

    ### Fuzzy CheckPoint

    > 进行部分脏页的刷新，有效循环利用Redo日志
    >

    #### Master Thread Checkpoint

    差不多已每秒或每十秒的速度从缓存池的脏页列表中刷新一定比例的页回磁盘。此操作是异步的，不会阻塞其他操作。

    #### FFLUSH_LRU_LIST Checkpoint

    flush_lru_list checkpoint是在单独的page cleaner线程中执行的。Buffer Pool的LRU空闲列表中保留一定数量的空闲页面，来保证Buffer Pool中有足够的空间应对新的数据库请求。

    在空闲列表不足时，发生flush_lru_list checkpoint，空闲数量阈值是可以配置的。（innbdb_lru_scan_depth）

    5.6 后放在单独的Page Cleaner线程中进行，不会阻塞用户查询线程

    #### Async/Sync Flush Checkpoint

    在重做日志文件不可用的情况是，需要强制将一些页刷新回磁盘。

    5.6 后放在单独的Page Cleaner线程中进行，不会阻塞用户查询线程。

    ​`​ Show Engine Innodb Status`​ 可以查看刷新次数和进行刷新的类型

    #### Dirty Page too much CheckPoint

    脏页的数量太多，导致InnoDB存储引擎强制进行Checkpoint。其目的总的来说还是为了保证缓冲池中有足够可用的页。

    可由参数`innodb_max_dirty_pages_pct`​控制，当缓冲池中脏页的数量占据75%时，强制进行Checkpoint，刷新一部分的脏页到磁盘。
